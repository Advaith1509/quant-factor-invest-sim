{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Portfolio Construction***\n",
        "We have already calculated the composite score, by giving equal weights to all the factors (i.e. 0.2) and just summing them up.\n",
        "\n",
        "Now we will continue through the following steps for constructing the portfolio -\n",
        "*   ***Stock Selection***\n",
        "*   ***Stock Weighting***\n",
        "*   ***Monthly Rebalancing***"
      ],
      "metadata": {
        "id": "jYsjhiZAMJsB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88tr11R7L9q8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_composite_scores = pd.read_csv('predicted_composite_scores.csv')\n",
        "volatility_scores = pd.read_csv('volatility_scores.csv')"
      ],
      "metadata": {
        "id": "9aelWZ2Xpza8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***1) Stock Selection***\n",
        "I'll be opting out the top-50 stocks on the basis of composite scores and then rebalancing them periodically.\n",
        "\n",
        "***Periodic Rebalancing*** *- As markets fluctuate, the weights of different assets or stocks in your portfolio naturally shift away from your original allocation. Without rebalancing, you may become unintentionally overexposed to certain assets that have outperformed, increasing your portfolioâ€™s risk beyond your intended tolerance*"
      ],
      "metadata": {
        "id": "3rrgqKharVd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We have set n=50 i.e., we are selecting the top 50 stocks with periodic rebalancing\n",
        "# rebalance_freq (str): Rebalancing frequency ('M' for monthly)\n",
        "def select_top_stocks(composite_scores, top_n=50, rebalance_freq='M'):\n",
        "    composite_scores['date'] = pd.to_datetime(composite_scores['date'])\n",
        "    composite_scores['rebalance_date'] = composite_scores['date'] + pd.offsets.MonthEnd(0)\n",
        "\n",
        "    top_stocks = (\n",
        "        composite_scores\n",
        "        .groupby('rebalance_date')\n",
        "        .apply(lambda x: x.nlargest(top_n, 'composite_score'))\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    return top_stocks[['symbol', 'rebalance_date', 'composite_score']]"
      ],
      "metadata": {
        "id": "Wimyou-nreZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***2) Stock Weighing***\n",
        "We'll use two methods for weighing the stocks -\n",
        "*   ***Equal Weighting -***  All selected stocks have the same weight.\n",
        "*   ***Risk Adjusted Weighing -*** Consider volatility for weighting. (Inverse of volatility)\n",
        "\n"
      ],
      "metadata": {
        "id": "7yQXpP3uczU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign equal weights to selected stocks\n",
        "def equal_weighting(selected_stocks):\n",
        "    df = selected_stocks.copy()\n",
        "    count = df.groupby('rebalance_date')['symbol'].transform('count')\n",
        "    df['weight'] = 1 / count\n",
        "    return df[['symbol', 'rebalance_date', 'weight']]"
      ],
      "metadata": {
        "id": "nUvLGcx9dWw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign weights based on inverse volatility (risk-adjusted)\n",
        "def risk_adjusted_weighting(selected_stocks, volatility_scores):\n",
        "    df = selected_stocks.copy()\n",
        "    volatility_scores['date'] = pd.to_datetime(volatility_scores['date'])\n",
        "    df = pd.merge(\n",
        "        df,\n",
        "        volatility_scores[['symbol', 'date', 'volatility_score']],\n",
        "        left_on=['symbol', 'rebalance_date'],\n",
        "        right_on=['symbol', 'date'],\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    # Fill missing volatilities with the mean for each rebalance date\n",
        "    df['volatility_score'] = df.groupby('rebalance_date')['volatility_score'].transform(\n",
        "        lambda x: x.fillna(x.mean())\n",
        "    )\n",
        "\n",
        "    # If all volatilities are missing for a date, fallback to equal weights\n",
        "    def assign_weights(group):\n",
        "        if group['volatility_score'].isnull().all():\n",
        "            group['weight'] = 1 / len(group)\n",
        "        else:\n",
        "            group['inv_vol'] = 1 / (group['volatility_score'] + 1e-8)\n",
        "            group['weight'] = group['inv_vol'] / group['inv_vol'].sum()\n",
        "        return group[['symbol', 'rebalance_date', 'weight']]\n",
        "    df = df.groupby('rebalance_date').apply(assign_weights).reset_index(drop=True)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "mGTupbZylixQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Portfolio Construction***"
      ],
      "metadata": {
        "id": "SvKlZkaxlmAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct portfolio with both weighting methods\n",
        "def construct_portfolio(composite_scores, volatility_scores, top_n=50):\n",
        "    top_stocks = select_top_stocks(predicted_composite_scores, top_n)\n",
        "    equal_weights = equal_weighting(top_stocks)\n",
        "    risk_weights = risk_adjusted_weighting(top_stocks, volatility_scores)\n",
        "\n",
        "    return {\n",
        "        'equal_weight_ml': equal_weights,\n",
        "        'risk_adjusted_ml': risk_weights\n",
        "    }"
      ],
      "metadata": {
        "id": "rd6RNQUxhJgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "portfolios = construct_portfolio(composite_scores, volatility_scores)\n",
        "portfolios['equal_weight_ml'].to_csv('equal_weight_portfolio_ml.csv', index=False)\n",
        "portfolios['risk_adjusted_ml'].to_csv('risk_adjusted_portfolio_ml.csv', index=False)"
      ],
      "metadata": {
        "id": "itKIvOtdnxyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0494d289-2c8f-4990-b08d-440bf1aaa31e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-35-2658524726.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda x: x.nlargest(top_n, 'composite_score'))\n",
            "/tmp/ipython-input-32-2063693045.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df = df.groupby('rebalance_date').apply(assign_weights).reset_index(drop=True)\n"
          ]
        }
      ]
    }
  ]
}